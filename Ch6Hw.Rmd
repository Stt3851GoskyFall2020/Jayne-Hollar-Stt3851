---
title: "Chapter 6 Homework ☺"
author: "Jayne Hollar"
date: "4/29/2020"
output: html_document
---
```{r, include=FALSE}
require(ISLR)
require(caret)
require(tidyverse)
library(glmnet)
library(pls)
```

9. In this exercise, we will predict the number of applications received
using the other variables in the College data set. 


```{r}
data(College)
?College
```

(a) Split the data set into a training set and a test set.

```{r}
set.seed(1)
nrow(College)
sample <- sample(1:777, 500)
train.data <- College[sample,]
test.data <- College[-sample,]
str(College)
```


(b) Fit a linear model using least squares on the training set, and report the test error obtained.


```{r}
lin.model <- lm(Apps ~ ., data = train.data)
summary(lin.model)
prediction <- predict(lin.model, test.data)

testerror<-mean((test.data$Apps-prediction)^2)
testerror
```

The test error is 904644.6 for the least squared model.

(c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained.


```{r}
train.matrix <- model.matrix(Apps~.,train.data)
test.matrix <- model.matrix(Apps~.,test.data)

grid<- 10^seq(10,-2,length=100)
ridge.mod <- glmnet(train.matrix, train.data$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
```
```{r}
set.seed(1)
cv.out <-cv.glmnet(train.matrix, train.data$Apps, alpha = 0, lambda = grid, thresh = 1e-12)
plot(cv.out)
```
```{r}
bestlam <- cv.out$lambda.min
bestlam
```
```{r}
ridge.pred <- predict(ridge.mod,s=bestlam,newx=test.matrix)

mean((test.data$Apps - ridge.pred)^2)
```

The mean squared error using the ridge regression model is 904637.5, which is slightly less than when using the least squared model.



(d) Fit a lasso model on the training set, with λ chosen by cross validation. Report the test error obtained, along with the number of non-zero coefficient estimates.
```{r}
lasso.mod <- glmnet(train.matrix,train.data$Apps,alpha=1,lambda=grid, thresh = 1e-12)
```

```{r}
set.seed(1)
cv.out <- cv.glmnet(train.matrix,train.data$Apps,alpha=1,lambda = grid,thresh=1e-12)
plot(cv.out)
```

```{r}
bestlam <- cv.out$lambda.min
bestlam
```
```{r}
lasso.pred=predict(lasso.mod,s=bestlam,newx=test.matrix)
mean((test.data$Apps - lasso.pred)^2)
```

```{r}
x=model.matrix(Apps~.,College)[,-1]
y=College$Apps
out=glmnet(x,y,alpha=1,lambda=grid)

lasso.coef=predict(out,type="coefficients",s=bestlam)[1:18,]
lasso.coef
```

There are 16 nonzero coefficient estimates when using the lasso model. The mean squared error is 904404.7, which is smaller than when using ridge regression or least squares.

(e) Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation.
```{r}
set.seed(1)
pcr.fit=pcr(Apps~., data=College,scale=TRUE,validation="CV")

summary(pcr.fit)
```

```{r}
pcr.fit<-pcr(Apps~.,data=train.data,scale=TRUE,validation="CV")

summary(pcr.fit)
```
```{r}
validationplot(pcr.fit,val.type="MSEP")
```
```{r}
pcr.pred<-predict(pcr.fit,test.data,ncomp=17)
mean((test.data$Apps-pcr.pred)^2)
```
Looking at the graph above, the value when M = 17 is the lowest, so we use 17 components. The cross validation error when using principal components regression is 904644.6, which is very closr to the error when using the least squared method.


(f) **Fit a Partial Least Squares model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation.**

```{r}
set.seed(1)

pls.fit=plsr(Apps~., data=train.data,scale=TRUE, validation="CV")

summary(pls.fit)
```
```{r}
validationplot(pls.fit,val.type="MSEP")
```
```{r}
pls.pred=predict(pls.fit,test.data,ncomp=10)

mean((test.data$Apps - pls.pred)^2)
```
This error obtained is higher when using partial least squares than the errors obtained when using the previous methods. According to the graph above, the error is minimized at M = 10. 

(g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?

**Test Errors: **

Least Square:904644.6

Ridge Regression:904637.5

Lasso:904405.7

PCR:904644.6

PLS:914799.1

The lasso model has the lowest mean squared error when compared to the other models, although they all predict similarly.
